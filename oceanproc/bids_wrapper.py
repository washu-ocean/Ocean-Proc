#!/usr/bin/env python3

from argparse import ArgumentParser
from pathlib import Path
import json
import os
import re
import shutil
import subprocess
from textwrap import dedent
import xml.etree.ElementTree as et
from .utils import exit_program_early, prompt_user_continue, prepare_subprocess_logging, debug_logging, log_linebreak, flags, run_subprocess
import logging
from bids import BIDSLayout
module_logger = logging.getLogger("fsspec")
module_logger.setLevel(logging.CRITICAL)

logger = logging.getLogger(__name__)
'''
remove_unusable -> relate xml and json with name and aqcuisition time (and series id?)
'''


@debug_logging
def remove_unusable_runs(xml_file:Path, bids_path:Path, subject:str, session:str):
    """
    Will remove unusable scans from list of scans after dcm2bids has run.

    :param xml_file: Path to XML file containing quality information generated by XNAT.
    :type xml_file: pathlib.Path
    :param bids_path: Path to directory containing BIDS-compliant raw data.
    :type bids_path: pathlib.Path
    :param subject: Subject ID used in BIDS-compliant data (for example, if 'sub-5000', subject is '5000').
    :type subject: str
    :param session: Session ID used in BIDS-compliant data (for example, if 'ses-01', session is '01').
    :type session: str

    """
    log_linebreak()
    logger.info("####### Removing the scans marked 'unusable' #######\n")

    # Try to delete based on "quality" key in sidecar files:
    bids_layout = BIDSLayout(bids_path, validate=False)
    data_files = bids_layout.get(subject=subject, session=session, extension="nii.gz", datatype=".*", regex_search=True)
    if len(data_files) == 0:
            exit_program_early("Could not find any data files in the bids directory.")

    files_to_delete = set()
    do_old_method = False
    for file in data_files:
        if "quality" not in file.entities:
            do_old_method = True
            break
        elif file.entities["quality"] == "unusable":
            files_to_delete.add(file)
            assoc_list = set(list(file.get_associations()) + [af for assoc in file.get_associations() for af in assoc.get_associations()])
            files_to_delete.update(assoc_list)
    
    if do_old_method:
        if not xml_file.exists():
            exit_program_early(f"Path {str(xml_file)} does not exist.")

        tree = et.parse(xml_file)
        prefix = "{" + str(tree.getroot()).split("{")[-1].split("}")[0] + "}"
        scan_element_list = list(tree.iter(f"{prefix}scans"))
        exp_element_list = list(tree.iter(f"{prefix}experiments"))
        study_id = exp_element_list[0][0].get("study_id")

        if len(scan_element_list) != 1:
            exit_program_early("Error parsing the xml file provided. Found none or more than one scan groups")

        scans = scan_element_list[0]
        quality_pairs = {}
        for s in scans:
            series_id = int(s.attrib['ID'])
            series_desc = s.attrib['type']
            protocol_name = s.find(f"{prefix}protocolName").text
            quality_info = s.find(f"{prefix}quality").text
            s_key = (series_id, series_desc, protocol_name)
            if s_key in quality_pairs and (quality_info == "unusable" or quality_pairs[s_key] == "unusable"):
                exit_program_early(f"Found scans with identical series numbers and protocol names in the session xml file. Cannot accurately differentiate these scans {s_key}")
            quality_pairs[s_key] = quality_info

        if len(quality_pairs) == 0:
            exit_program_early("Could not find scan quality information in the given xml file.")

        logger.info("scan quality information: ")
        for k, v in quality_pairs.items():
            logger.info(f"\t{k} -> {v}")

        for file in data_files:
            if flags.longitudinal and file.entities["study_id"] != study_id:
                continue
            try:
                j_key = (file.entities["SeriesNumber"], file.entities["SeriesDescription"], file.entities["ProtocolName"])
                if j_key in quality_pairs and quality_pairs[j_key] == "unusable":
                    files_to_delete.add(file)
                    assoc_list = set(list(file.get_associations()) + [af for assoc in file.get_associations() for af in assoc.get_associations()])
                    files_to_delete.update(assoc_list)
            except KeyError:
                logger.warning(f"Could not find all key fields for file: \n\t NIFTI:{file.path} -- Continuing...")

    for file in sorted(files_to_delete, key=lambda x: x.path):
        if Path(file.path).exists():
            logger.info(f"  Removing file: {file.path}")
            os.remove(file.path)



@debug_logging
def run_dcm2bids(subject:str,
                 session:str,
                 nifti_dir:Path,
                 bids_output_dir:Path,
                 config_file:Path,
                 nordic_config:Path = None,
                 skip_validate:bool = False):
    """
    Run dcm2bids with a given set of parameters.

    :param subject: Subject name (ex. 'sub-5000', subject would be '5000')
    :type subject: str
    :param session: Session name (ex. 'ses-01', session would be '01')
    :type session: str
    :param nifti_dir: Path to the directory where NIFTI data for this session is kept.
    :type nifti_dir: pathlib.Path
    :param bids_output_dir: Path to the bids directory to store the newly made NIFTI files
    :type bids_output_dir: pathlib.Path
    :param config_file: Path to dcm2bids config file, which maps raw sourcedata to BIDS-compliant counterpart
    :type config_file: pathlib.Path
    :param nordic_config: Path to second dcm2bids config file, needed for additional post processing that one BIDS config file can't handle.
    :type nordic_config: pathlib.Path
    :raise RuntimeError: If dcm2bids exits with a non-zero exit code.
    """
    title = "dcm2bids"

    if shutil.which('dcm2bids') is None:
        exit_program_early(f"Cannot locate program '{title}', make sure it is in your PATH.")

    helper_command = f"""{shutil.which('dcm2bids')}
                    {'--bids_validate' if skip_validate is False else ''}
                    --skip_dcm2niix
                    -d {str(nifti_dir)}
                    -p {subject}
                    -s {session}
                    -c {str(config_file)}
                    -o {str(bids_output_dir)}
                    """
    try:
        log_linebreak()
        logger.info("####### Running first round of Dcm2Bids ########\n")
        run_subprocess(helper_command, title=title)
        if nordic_config:
            if not nordic_config.exists():
                exit_program_early(f"Path {nordic_config} does not exist.")

            nordic_run_command = f"""{shutil.which('dcm2bids')}
                                    --bids_validate
                                    --skip_dcm2niix
                                    -d {str(nifti_dir)}
                                    -p {subject}
                                    -s {session}
                                    -c {str(nordic_config)}
                                    -o {str(bids_output_dir)}
                                    """
            log_linebreak()
            logger.info("####### Running second round of Dcm2Bids ########\n")
            run_subprocess(nordic_run_command, title=title)

            # Clean up NORDIC files
            separate_nordic_files = bids_output_dir.glob(f"sub-{subject}/ses-{session}/func/*_part-*")
            logger.debug("removing the old nordic files that are not needed after mag-phase combination :")
            for f in separate_nordic_files:
                logger.debug(f"deleting file: {f}")
                os.remove(f)

    except RuntimeError or subprocess.CalledProcessError as e:
        prepare_subprocess_logging(logger, stop=True)
        logger.exception(e, stack_info=True)
        exit_program_early(f"Problem running '{title}'.")


@debug_logging
def run_dcm2niix(source_dir:Path,
                 tmp_nifti_dir:Path,
                 clean_up_func=None):
    """
    Run dcm2niix with the given input and output directories.

    :param source_dir: Path to 'sourcedata' directory (or wherever DICOM data is kept).
    :type source_dir: pathlib.Path
    :param tmp_nifti_dir: Path to the directory to store the newly made NIFTI files
    :type tmp_nifti_dir: pathlib.Path
    """
    title = "dcm2niix"

    if not source_dir.exists():
        exit_program_early(f"Path {source_dir} does not exist.")
    elif shutil.which('dcm2niix') is None:
        exit_program_early(f"Cannot locate program '{title}', make sure it is in your PATH.")

    if not tmp_nifti_dir.exists():
        tmp_nifti_dir.mkdir(parents=True)

    helper_command = f"""{shutil.which('dcm2niix')}
                        -b y
                        -ba y
                        -z y
                        -f %3s_%f_%p_%t
                        -o {str(tmp_nifti_dir)}
                        {str(source_dir)}
                        """
    try:
        log_linebreak()
        logger.info("####### Converting DICOM files into NIFTI #######\n")
        run_subprocess(helper_command, title=title)
    except RuntimeError or subprocess.CalledProcessError as e:
        prepare_subprocess_logging(logger, stop=True)
        logger.exception(e, stack_info=True)
        exit_program_early(f"Problem running '{title}'.",
                           exit_func=clean_up_func if clean_up_func else None)

    # Delete or move extra files from short runs
    files_to_remove = list(tmp_nifti_dir.glob("*a.nii.gz")) + list(tmp_nifti_dir.glob("*a.json"))
    if flags.debug:
        unused_files_dir = tmp_nifti_dir.parent / f"{tmp_nifti_dir.name}_unused"
        unused_files_dir.mkdir(exist_ok=True)
        logger.debug(f"moving some unused files and files created from shortened runs to directory {unused_files_dir}")
        for f in files_to_remove:
            shutil.move(f.resolve(), (unused_files_dir / f.name).resolve())
    else:
        logger.info(f"removing some unused files and files created from shortened runs :\n  {[str(f) for f in files_to_remove]}")
        for f in files_to_remove:
            os.remove(f)


def match_xml_to_nifti(nifti_dir:Path, xml_path:Path):
    logger.info("####### Matching the correct xml file and usability to each session #######\n")
    if not xml_path.exists():
        exit_program_early(f"Path {str(xml_path)} does not exist.")
    tree = et.parse(xml_path)
    prefix = "{" + str(tree.getroot()).split("{")[-1].split("}")[0] + "}"
    scan_element_list = list(tree.iter(f"{prefix}scans"))
    exp_element_list = list(tree.iter(f"{prefix}experiments"))
    study_id = exp_element_list[0][0].get("study_id")

    if len(scan_element_list) != 1:
        exit_program_early("Error parsing the xml file provided. Found none or more than one scan groups")

    logger.info(f"file pairing: \n\txml -> {xml_path} \n\tNIFTIs -> {nifti_dir}")   
    logger.info("scan quality information: ")
    scans = scan_element_list[0]
    quality_pairs = {}
    for s in scans:
        series_id = int(s.attrib['ID'])
        series_desc = s.attrib['type']
        quality_info = s.find(f"{prefix}quality").text
        quality_pairs[series_id] = quality_info
        logger.info(f"\t({series_id, series_desc}) -> {quality_info}")

    session_jsons = list(nifti_dir.glob("*.json"))
    for sidecar in session_jsons:
        jd = None
        with sidecar.open("r") as f:
            jd = json.load(f)
        jd["study_id"] = study_id
        if jd["SeriesNumber"] in quality_pairs:
            jd["quality"] = quality_pairs[jd["SeriesNumber"]]
        else:
            logger.warning(f"Cannot find the Series Number - {jd['SeriesNumber']} - in the session xml. Marking the file - {sidecar} - as 'unusable'")
            jd["quality"] = "unusable"
        with sidecar.open("w") as f:
            json.dump(jd, f, indent=4)


@debug_logging
def extend_session(subject:str,
                   session:str,
                   tmp_dir:Path,
                   bids_dir:Path):

    if (tmp_ses_dcm_dir := tmp_dir / "tmp_dcm2bids").exists():
        logger.debug(f"removing the tmp_dcm2bids directory at the path: {tmp_ses_dcm_dir}")
        shutil.rmtree(tmp_ses_dcm_dir)

    bids_layout = BIDSLayout(bids_dir, validate=False)
    tmp_layout = BIDSLayout(tmp_dir, validate=False)

    for tmp_file in tmp_layout.get(subject=subject, session=session, datatype=".*", regex_search=True):
        if "tmp_dcm2bids" in tmp_file.path:
            continue
        tmp_ent = tmp_file.get_entities()
        if "run" in tmp_ent:
            del tmp_ent["run"]
        tmp_run_num = int(tmp_file.entities['run']) if 'run' in tmp_file.entities else 1
        similar_files = bids_layout.get(**tmp_ent)
        if len(similar_files) == 0:
            tmp_new_path = bids_layout.build_path(tmp_file.get_entities())
            Path(tmp_new_path).parent.resolve().mkdir(parents=True, exist_ok=True)  # Make sure folder exists if not already created (e.g. 'fmap/')
            logger.info(f"moving file: {tmp_file.path} to: {tmp_new_path}")
            shutil.move(tmp_file.path, tmp_new_path)
            continue
        run_nums = [f.entities['run'] for f in similar_files if 'run' in f.entities]
        max_bids_run = 1 if len(run_nums) == 0 else int(max(run_nums))
        tmp_ent['run'] = f"{(max_bids_run+tmp_run_num):02d}"
        tmp_new_path = bids_layout.build_path(tmp_ent)
        logger.info(f"moving file: {tmp_file.path} to: {tmp_new_path}")
        shutil.move(tmp_file.path, tmp_new_path)
        if (len(similar_files) == 1) and ('run' not in similar_files[0].entities):
            bids_file_ents = similar_files[0].get_entities()
            bids_file_ents['run'] = f"{(max_bids_run):02d}"
            bids_new_path = bids_layout.build_path(bids_file_ents)
            Path(bids_new_path).parent.resolve().mkdir(parents=True, exist_ok=True)  # Make sure folder exists if not already created (e.g. 'fmap/')
            logger.info(f"moving file: {similar_files[0].path} to: {bids_new_path}")
            shutil.move(similar_files[0].path, bids_new_path)


@debug_logging
def dicom_to_bids(subject:str,
                  session:str,
                  source_dir:Path,
                  bids_dir:Path,
                  xml_path:Path,
                  bids_config:Path,
                  nordic_config:Path = None,
                  nifti:bool = False,
                  skip_validate:bool = False,
                  skip_prompt:bool = False):
    """
    Facilitates the conversion of DICOM data into NIFTI data in BIDS format, and the removal of data marked 'unusable'.

    :param subject: Subject name (ex. 'sub-5000', subject would be '5000')
    :type subject: str
    :param session: Session name (ex. 'ses-01', session would be '01')
    :type session: str
    :param source_dir: Path to 'sourcedata' directory (or wherever DICOM data is kept).
    :type source_dir: pathlib.Path
    :param bids_dir: Path to the bids directory to store the newly made NIFTI files
    :type bids_dir: pathlib.Path
    :param bids_config: Path to dcm2bids config file, which maps raw sourcedata to BIDS-compliant counterpart
    :type bids_config: pathlib.Path
    :param nordic_config: Path to second dcm2bids config file, needed for additional post processing if NORDIC data that one BIDS config file can't handle.
    :type nordic_config: pathlib.Path
    :param nifti: Specify that the soure directory contains NIFTI files instead of DICOM
    :type nifti: bool
    """

    for p in [source_dir, bids_dir, bids_config]:
        if not p.exists():
            exit_program_early(f"Path {str(p)} does not exist.")

    if (path_that_exists := bids_dir / f"sub-{subject}/ses-{session}").exists() and (not skip_prompt):
        ans = prompt_user_continue(dedent("""
                                        A raw data bids path for this subject and session already exists.
                                        Would you like to delete its contents and rerun dcm2bids? If not,
                                        dcm2bids will be skipped.
                                            """))
        if ans:
            logger.debug("removing the old BIDS raw data directory and its contents")
            shutil.rmtree(path_that_exists)
        else:
            return

    tmp_path = bids_dir / f"tmp_dcm2bids/sub-{subject}_ses-{session}"

    def clean_up(quiet=False):
        try:
            logger.debug(f"removing the temporary directory used by dcm2bids: {tmp_path}")
            shutil.rmtree(tmp_path)
        except Exception:
            if not quiet:
                logger.warning(f"There was a problem deleting the temporary directory at {tmp_path}")

    nifti_path = None
    clean_up(quiet=True)
    if not nifti:
        run_dcm2niix(source_dir=source_dir,
                     tmp_nifti_dir=tmp_path)
        nifti_path = tmp_path
    else:
        nifti_path = source_dir

    # if flags.longitudinal:
    #     match_xml_to_nifti(nifti_dir=nifti_path,
    #                        xml_path=xml_path)

    match_xml_to_nifti(nifti_dir=nifti_path,
                       xml_path=xml_path)

    run_dcm2bids(subject=subject,
                 session=session,
                 nifti_dir=nifti_path,
                 bids_output_dir=bids_dir,
                 config_file=bids_config,
                 nordic_config=nordic_config,
                 skip_validate=skip_validate)

    if not flags.debug:
        clean_up()


if __name__ == "__main__":
    parser = ArgumentParser(prog="bids_wrapper.py",
                            description="wrapper script for dcm2bids",
                            epilog="WIP")
    parser.add_argument("-su", "--subject", required=True,
                        help="Subject ID")
    parser.add_argument("-se","--session", required=True,
                        help="Session ID")
    parser.add_argument("-sd", "--source_data", type=Path, required=True,
                        help="Path to directory containing this session's DICOM files")
    parser.add_argument("-b", "--bids_path", type=Path, required=True,
                        help="Path to the bids directory to store the newly made NIFTI files")
    parser.add_argument("-x", "--xml_path", type=Path, required=True,
                        help="Path to this session's XML file")
    parser.add_argument("-c", "--bids_config", type=Path, required=True,
                        help="dcm2bids config json file")
    parser.add_argument("-n", "--nordic_config", type=Path,
                        help="Second dcm2bids config json file used for NORDIC processing")
    parser.add_argument("--nifti", action='store_true',
                        help="Flag to specify that the source directory contains files of type NIFTI (.nii/.jsons) instead of DICOM")
    parser.add_argument("--skip_bids_validation", action="store_true",
                        help="Specifies skipping BIDS validation (only enabled for fMRIprep step)")
    args = parser.parse_args()

    dicom_to_bids(subject=args.subject,
                  session=args.session,
                  source_dir=args.source_data,
                  bids_dir=args.bids_path,
                  xml_path=args.xml_path,
                  bids_config=args.bids_config,
                  nordic_config=args.nordic_config,
                  nifti=args.nifti,
                  skip_validate=args.skip_bids_validation)
