#!/usr/bin/env python3

import json
from datetime import datetime
import argparse
import re
from pathlib import Path
import xml.etree.ElementTree as et
from bids import BIDSLayout
from .utils import exit_program_early, debug_logging, log_linebreak
import logging
module_logger = logging.getLogger("fsspec")
module_logger.setLevel(logging.CRITICAL)

logger = logging.getLogger(__name__)

@debug_logging
def get_locals_from_xml(xml_path: Path) -> tuple[set, str]:
    """
    Read in the xml file to find the localizers.

    :param xml_path: Path to XML generated by XNAT
    :type xml_path: pathlib.Path
    :return: Set containing all localizer IDs
    :rtype: set
    """
    tree = et.parse(xml_path)
    prefix = "{" + str(tree.getroot()).split("{")[-1].split("}")[0] + "}"
    scan_element_list = list(tree.iter(f"{prefix}scans"))
    exp_element_list = list(tree.iter(f"{prefix}experiments"))
    study_id = exp_element_list[0][0].get("study_id")
    
    if len(scan_element_list) != 1:
        exit_program_early(f"Error parsing the xml file provided. Found none or more than one scan groups")
    
    scans = scan_element_list[0]
    
    localizers = set()
    for s in scans:
        if re.match(r"Localizer.*", s.get("type")) and s.find(f'{prefix}quality').text == "usable":
            acq_time = datetime.strptime(s.find(f"{prefix}startTime").text, "%H:%M:%S")
            series_id = int(s.get("ID"))
            localizers.add((acq_time, series_id))
    return (sorted(localizers), study_id)


def get_func_from_bids(bids_layout: BIDSLayout,
                       subject:str,
                       session:str,
                       localizers: set,
                       study_id:str,
                    #    json_dict: defaultdict[list],
                       groupings: list[dict[str:set]]):
    
    func_files = bids_layout.get(subject=subject, session=session, suffix="bold", datatype="func", extension="nii.gz")
    if len(func_files) == 0:
        exit_program_early("Could not find any functional BOLD files for this subject and session.")
    
    for bold_file in func_files:
        if bold_file.entities["study_id"] != study_id:
            continue

        acq_time = datetime.strptime(bold_file.entities["AcquisitionTime"], "%H:%M:%S.%f")
        for i, (dt, series_id) in enumerate(localizers):
            if i < len(localizers)-1:
                if (acq_time > dt and acq_time < localizers[i+1][0]) and bold_file.entities["SeriesNumber"] > series_id:
                    groupings[i]["task"].add((bold_file, acq_time))
                    break
            else:
                groupings[i]["task"].add((bold_file, acq_time))


def get_fmap_from_bids(bids_layout: BIDSLayout,
                       subject:str,
                       session:str,
                       localizers: set,
                       study_id:str,
                    #    json_dict: defaultdict[list],
                       groupings: list[dict[str:set]]):
    
    fmap_files = bids_layout.get(subject=subject, session=session, suffix="epi", datatype="fmap", extension="nii.gz")
    if len(fmap_files) == 0:
        exit_program_early("Could not find any fieldmap files for this subject and session.")

    for epi_file in fmap_files:
        if epi_file.entities["study_id"] != study_id:
            continue

        acq_time = datetime.strptime(epi_file.entities["AcquisitionTime"], "%H:%M:%S.%f")
        direction = f"fmap{epi_file.entities['direction']}"
        for i, (dt, series_id) in enumerate(localizers):
            if i < len(localizers)-1:
                if (acq_time > dt and acq_time < localizers[i+1][0]) and epi_file.entities["SeriesNumber"] > series_id:
                    groupings[i][direction].add((epi_file, acq_time))
                    break
            else:
                groupings[i][direction].add((epi_file, acq_time))


@debug_logging
def map_fmap_to_func(subject:str,
                     session:str,
                     bids_path:Path,
                     xml_path: Path):
    
    if not xml_path.is_file():
        exit_program_early(f"Session xml file {xml_path} does not exist.")
    layout = BIDSLayout(bids_path, validate=False)
    locals_series, study_id = get_locals_from_xml(xml_path=xml_path)
    logger.info(f"Localizers: {locals_series}")

    groups = [{"task":set(), "fmapAP": set(), "fmapPA": set()} for _ in locals_series]
    get_func_from_bids(bids_layout=layout,
                       subject=subject,
                       session=session,
                       localizers=locals_series,
                       study_id=study_id,
                       groupings=groups)
    
    get_fmap_from_bids(bids_layout=layout,
                       subject=subject,
                       session=session,
                       localizers=locals_series,
                       study_id=study_id,
                       groupings=groups)
    
    logger.info(f"Localizer groups: ") 
    for group_num, g in enumerate(groups):
        logger.info(f"\tgroup : {group_num}")
        for k, v in g.items():
            logger.info(f"\t\t{k}: {v}")

    for group in groups:
        if len(group["fmapAP"]) != len(group["fmapPA"]):
            exit_program_early("Unequal number of AP and PA field maps.")
        fmap_pairs = tuple(zip(sorted(group["fmapAP"], key=lambda x: x[1]), sorted(group["fmapPA"], key=lambda x: x[1])))
        fmap_times = []

        # get times for field maps
        for i, ((ap_file, ap_acq_time), (pa_file, pa_acq_time)) in enumerate(fmap_pairs):
            times = sorted((ap_acq_time, pa_acq_time))
            fmap_times.append(times[0] + (abs(times[1] - times[0])/2))

        # pair task runs with field maps based on closest Acquisition Time
        map_pairings = {s:[] for s in fmap_pairs}
        for (t_file, t_acq_time) in group["task"]:
            diff = list(map(lambda x: abs(x-t_acq_time), fmap_times))
            pairing = fmap_pairs[diff.index(min(diff))]
            map_pairings[pairing].append(t_file)

        # add the list of task run files that are paired with each field map in their json files
        pairing_strs = []
        for (ap_tup, pa_tup), task_files in map_pairings.items():
            for fmap_file, fmap_type in ((ap_tup[0], "ap"), (pa_tup[0], "pa")):
                fmap_json = [f for f in fmap_file.get_associations() if f.entities['extension'] == ".json"]
                if len(fmap_json) != 1:
                    exit_program_early(f"Cannot find the associated JSON file for fmap: {fmap_file.filename}")
                fmap_json = fmap_json[0]
                intended_for = [tf.relpath.split("/", 1)[-1] for tf in task_files]
                task_series = set([f"{tf.filename}({str(tf.entities['SeriesNumber'])})" for tf in task_files])
                jd = fmap_json.get_dict()
                jd["IntendedFor"] = intended_for
                with open(fmap_json.path, "w") as out_file:
                    logger.debug(f"writing field map pairing information to file: {fmap_json.filename}")
                    out_file.write(json.dumps(jd, indent=4))
                pairing_strs.append((f"{fmap_file.filename}:{jd['SeriesNumber']}", ' '.join(task_series)))

        # report the fieldmap pairings           
        if len(pairing_strs) > 0:            
            logger.info(f"Field map pairings:")
            for ps in pairing_strs:
                logger.info(f"{ps[0]} -->  {ps[1]}")


def map_fmap_to_func_with_pairing_file(bids_dir_path: Path,
                                       pairing_json: Path):
    log_linebreak()
    for json_path in bids_dir_path.glob("fmap/*json"): # reset IntendedFor field in all fmap json
        with open(json_path) as f:
            json_obj = json.load(f)
        json_obj["IntendedFor"] = []
        with open(json_path, "w") as f:
            json.dump(json_obj, f, indent=4)
    logger.info("####### Pairing field maps to functional runs using pairing file #######\n")
    with pairing_json.open() as f:
        pairing_dict = json.load(f)
    pairings_list = pairing_dict["pairings"]
    for pairing in pairings_list:
        fmap_jsons = bids_dir_path.glob(f"fmap/*{pairing['fmap']}*json")
        func_paths = []
        for func in pairing["func"]:
            func_paths.extend(
                [str(p.relative_to(bids_dir_path.parent)) for p in bids_dir_path.parent.glob(f"*/func/*{func}*nii.gz")]
            )
        for fmap_json in fmap_jsons:
            with fmap_json.open() as f:
                fmap_dict = json.load(f)
            fmap_dict["IntendedFor"] = func_paths
            with fmap_json.open('w') as f:
                json.dump(fmap_dict, f, indent=4)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        prog="group_series.py", 
        description="Grouping field maps to BOLD task runs"
    )
    parser.add_argument("xml_ses_file", type=Path, help="The path to the xml file for this session")
    parser.add_argument("bids_ses_dir", type=Path, help="The path to the bids directory for this session")
    args = parser.parse_args()

    map_fmap_to_func(xml_path=args.xml_ses_file, 
                     bids_dir_path=args.bids_ses_dir)
